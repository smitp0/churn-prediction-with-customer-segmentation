{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "150f7a24",
   "metadata": {},
   "source": [
    "# MRP PROJECT\n",
    "\n",
    "   Customer churn prediction models have been proven to provide companies the ability to determine if a customer will churn based on a variety of factors. However, this space still has room for improvement and this project aims to determine if a customer churn prediction accuracy can be improved through the use of customer segmentation by cluster groups of customers based on similarities in their buying patterns and company engagement behaviours. Through this process, companies will also gain the ability to better understand which variables lead to a higher churn rate while also being able to use these clusters for ulterior targeted marketing initiatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a99d1b",
   "metadata": {},
   "source": [
    "### Importing packages and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eca0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix,f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c647ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c0adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5ad54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetFeature = 'churn_risk_score'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff849e1",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a164c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,8))\n",
    "sns.color_palette(\"Spectral\", as_cmap=True)\n",
    "sns.set_style('white')\n",
    "sns.countplot(data=final_df_train.sort_values(by='feedback'), x='feedback', hue='churn_risk_score', palette = 'Spectral_r')\n",
    "plt.xlabel('Feedback', labelpad = 15,  fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Total Feedback', labelpad = 15, fontsize=14)\n",
    "plt.title('Count of Feedback Type based on Churn Risk Score', y = 1.02,  fontsize=18, fontweight = 'bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab23be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,8))\n",
    "sns.color_palette(\"Spectral\", as_cmap=True)\n",
    "sns.set_style('white')\n",
    "sns.countplot(data=final_df_train.sort_values(by='churn_risk_score'), x='churn_risk_score', hue='gender',palette=['#f699cd',\"#6495ED\"])\n",
    "plt.xlabel('Churn Risk Score', labelpad = 15,  fontsize=14);\n",
    "plt.ylabel('Total Count ', labelpad = 15, fontsize=14);\n",
    "plt.title('Count of Gender based on Churn Risk Score', y = 1.02,  fontsize=18, fontweight = 'bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eb70c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,8))\n",
    "sns.color_palette(\"Spectral\", as_cmap=True)\n",
    "sns.set_style('white')\n",
    "sns.countplot(data=final_df_train.sort_values(by='membership_category'), x='membership_category', hue='churn_risk_score', palette='Spectral_r')\n",
    "plt.xlabel('Membership Type', labelpad = 15,  fontsize=14);\n",
    "plt.ylabel('Total Count of Memberships', labelpad = 15, fontsize=14);\n",
    "plt.title('Count of Membership Type based on Churn Risk Score', y = 1.02,  fontsize=18, fontweight = 'bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b003787",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,8))\n",
    "sns.set_style('white')\n",
    "sns.heatmap(df_train.corr(), vmax=1, vmin=-1, annot=True, cmap='vlag')\n",
    "plt.title('Correlation Plot for Numerical Variables', y = 1.02,  fontsize=18, fontweight = 'bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e305e3",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1852c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abac2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['gender'] = df_train['gender'].replace('Unknown',np.NaN) # replace Unknown with NaN for further imputing\n",
    "df_train['joined_through_referral'] = df_train['joined_through_referral'].replace('?',np.NaN) # replace ? with NaN for further imputing\n",
    "df_train['referral_id'] = df_train['referral_id'].replace('xxxxxxxx',np.NaN)  # replace xxxxx with NaN for further imputing\n",
    "df_train['medium_of_operation'] = df_train['medium_of_operation'].replace('?',np.NaN) # replace ? with NaN for further imputing\n",
    "df_train['days_since_last_login'] = df_train['days_since_last_login'].replace(-999,np.NaN)  # replace -999 with NaN for further imputing\n",
    "df_train.loc[~(df_train['avg_time_spent'] > 0), 'avg_time_spent']=np.nan # replace all negative values with NaN for further imputing\n",
    "df_train.loc[~(df_train['points_in_wallet'] > 0), 'points_in_wallet']=np.nan # replace all negative values with NaN for further imputing\n",
    "\n",
    "df_train['avg_frequency_login_days'] = df_train['avg_frequency_login_days'].replace('Error',np.NaN) # replace Error with NaN for further imputing\n",
    "df_train['avg_frequency_login_days']=df_train['avg_frequency_login_days'].astype('float')\n",
    "df_train.loc[~(df_train['avg_frequency_login_days'] > 0), 'avg_frequency_login_days']=np.nan # replace all negative values with NaN for further imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0bf38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## based on research, mode is best for imputing for categorical variables with a small number of unique values, which \n",
    "## is the case in this dataset, as is with most categorical variables\n",
    "cat_var_imputing = df_train[['gender','region_category','joined_through_referral','preferred_offer_types','medium_of_operation',]]\n",
    "for i, variable in enumerate(cat_var_imputing):\n",
    "    df_train[variable].fillna(df_train[variable].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17fa63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## based on research, for numerical variables, KNN imputing is preferred:\n",
    "### In this approach, we specify a distance from the missing values which is also known as the K parameter. \n",
    "## The missing value will be predicted in reference to the mean of the neighbours. It is implemented by the KNNimputer() method\n",
    "\n",
    "num_imputing = df_train[['points_in_wallet','avg_time_spent','days_since_last_login','avg_frequency_login_days']]\n",
    "imp = KNNImputer(n_neighbors=2)\n",
    "imputed_vals=imp.fit_transform(num_imputing)\n",
    "\n",
    "temp_dataset = pd.DataFrame({\n",
    "    'points_in_wallet':imputed_vals.T[0],\n",
    "    'avg_time_spent':imputed_vals.T[1],\n",
    "    'days_since_last_login':imputed_vals.T[2],\n",
    "    'avg_frequency_login_days':imputed_vals.T[3]\n",
    "\n",
    "})\n",
    "\n",
    "df_train.drop(['points_in_wallet','avg_time_spent','days_since_last_login','avg_frequency_login_days'], axis=1, inplace=True)\n",
    "\n",
    "final_df_train = pd.concat([df_train, temp_dataset], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3fa3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6e913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5295fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['gender'] = df_test['gender'].replace('Unknown',np.NaN) # replace Unknown with NaN for further imputing\n",
    "df_test['joined_through_referral'] = df_test['joined_through_referral'].replace('?',np.NaN) # replace ? with NaN for further imputing\n",
    "df_test['referral_id'] = df_test['referral_id'].replace('xxxxxxxx',np.NaN)  # replace xxxxx with NaN for further imputing\n",
    "df_test['medium_of_operation'] = df_test['medium_of_operation'].replace('?',np.NaN) # replace ? with NaN for further imputing\n",
    "df_test['days_since_last_login'] = df_test['days_since_last_login'].replace(-999,np.NaN)  # replace -999 with NaN for further imputing\n",
    "df_test.loc[~(df_test['avg_time_spent'] > 0), 'avg_time_spent']=np.nan # replace all negative values with NaN for further imputing\n",
    "df_test.loc[~(df_test['points_in_wallet'] > 0), 'points_in_wallet']=np.nan # replace all negative values with NaN for further imputing\n",
    "\n",
    "df_test['avg_frequency_login_days'] = df_test['avg_frequency_login_days'].replace('Error',np.NaN) # replace Error with NaN for further imputing\n",
    "df_test['avg_frequency_login_days']=df_test['avg_frequency_login_days'].astype('float')\n",
    "df_test.loc[~(df_test['avg_frequency_login_days'] > 0), 'avg_frequency_login_days']=np.nan # replace all negative values with NaN for further imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## based on research, mode is best for imputing for categorical variables with a small number of unique values, which \n",
    "## is the case in this dataset, as is with most categorical variables\n",
    "cat_var_imputing = df_test[['gender','region_category','joined_through_referral','preferred_offer_types','medium_of_operation',]]\n",
    "for i, variable in enumerate(cat_var_imputing):\n",
    "    df_test[variable].fillna(df_test[variable].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc7ffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## based on research, for numerical variables, KNN imputing is preferred:\n",
    "### In this approach, we specify a distance from the missing values which is also known as the K parameter. \n",
    "## The missing value will be predicted in reference to the mean of the neighbours. It is implemented by the KNNimputer() method\n",
    "\n",
    "num_imputing_test = df_test[['points_in_wallet','avg_time_spent','days_since_last_login','avg_frequency_login_days']]\n",
    "imp_test = KNNImputer(n_neighbors=2)\n",
    "imputed_vals_test=imp_test.fit_transform(num_imputing_test)\n",
    "\n",
    "temp_dataset2 = pd.DataFrame({\n",
    "    'points_in_wallet':imputed_vals_test.T[0],\n",
    "    'avg_time_spent':imputed_vals_test.T[1],\n",
    "    'days_since_last_login':imputed_vals_test.T[2],\n",
    "    'avg_frequency_login_days':imputed_vals_test.T[3]\n",
    "\n",
    "})\n",
    "\n",
    "df_test.drop(['points_in_wallet','avg_time_spent','days_since_last_login','avg_frequency_login_days'], axis=1, inplace=True)\n",
    "\n",
    "final_df_test = pd.concat([df_test, temp_dataset2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0294b2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9628bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df_train['days_since_last_login'] = final_df_train['days_since_last_login'].astype('int64')\n",
    "final_df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef902fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_test['days_since_last_login'] = final_df_test['days_since_last_login'].astype('int64')\n",
    "final_df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e8d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting rid of negative churn risk\n",
    "negative_churn = np.where(final_df_train['churn_risk_score'] == -1)\n",
    "final_df_train.drop(negative_churn[0],inplace=True)\n",
    "final_df_train.index = range(0,final_df_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13facca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding year variable to training and testing df\n",
    "final_df_train['year']=final_df_train.joining_date.apply(lambda k:2021-int(k.split('-')[0]))\n",
    "final_df_test['year']=final_df_test.joining_date.apply(lambda k:2021-int(k.split('-')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dd7280",
   "metadata": {},
   "source": [
    "### Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122d8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_outliers=final_df_train.select_dtypes(include=[np.number])\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3,ncols=3,figsize=(20, 15)) \n",
    "for variable, subplot in zip(final_df_outliers.columns, ax.flatten()):\n",
    "    z = sns.boxplot(x = final_df_outliers[variable], orient = \"h\" , ax=subplot, flierprops={\"marker\": \"x\"}, \n",
    "                    medianprops={\"color\": \"#f03a2e\"}, dodge=False, palette = ['#4296f5'])\n",
    "    z.set_xlabel(variable, fontsize = 14, fontweight = 'bold')\n",
    "fig.delaxes(ax[2][2])\n",
    "fig.suptitle('Boxplot for Numerical Variables before Outlier Removal', y = 0.91,  fontsize=18, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095107da",
   "metadata": {},
   "source": [
    "From the above, it can be seen that avg_transaction_value, points_in_wallet, avg_time_spent and avg_frequency_login_days all have outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694543c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = final_df_train.quantile(0.25) \n",
    "Q3 = final_df_train.quantile(0.75) \n",
    "IQR = Q3 - Q1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f376211",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_train_iqr = final_df_train[~((final_df_train < (Q1 - 1.5 * IQR)) |(final_df_train > (Q3 + 1.5 * IQR))).any(axis=1)] \n",
    "final_data_train_iqr.reset_index(inplace=True)\n",
    "final_data_train_iqr.drop('index',axis=1, inplace=True)\n",
    "final_data_train_iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace0fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AFTER REMOVING OUTLIERS:\n",
    "final_df_outliers2=final_data_train_iqr.select_dtypes(include=[np.number])\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3,ncols=3,figsize=(20, 15)) \n",
    "for variable, subplot in zip(final_df_outliers2.columns, ax.flatten()):\n",
    "    z = sns.boxplot(x = final_df_outliers2[variable], orient = \"h\", ax=subplot, flierprops={\"marker\": \"x\"}, \n",
    "                medianprops={\"color\": \"#f03a2e\"}, dodge=False, palette = ['#4296f5']) \n",
    "    z.set_xlabel(variable, fontsize = 14, fontweight = 'bold')\n",
    "fig.delaxes(ax[2][2])\n",
    "fig.suptitle('Boxplot for Numerical Variables after Outlier Removal', y = 0.91,  fontsize=18, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9cf0e2",
   "metadata": {},
   "source": [
    "### Categorical Encoding and Balancing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdf9da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_train['churn_risk_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b3505",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['gender','region_category','membership_category','joined_through_referral',\n",
    "      'preferred_offer_types','medium_of_operation','internet_option','used_special_discount',\n",
    "       'offer_application_preference','past_complaint','complaint_status','feedback']\n",
    "df_train_balanced = final_df_train[cats]\n",
    "df_test_balanced = final_df_test[cats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5de904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical encoding of newly created test and training dataset\n",
    "df_train_balanced = pd.get_dummies(df_train_balanced)\n",
    "df_test_balanced = pd.get_dummies(df_test_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73acaa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_train = ['days_since_last_login','avg_time_spent','avg_transaction_value','avg_frequency_login_days',\n",
    "'points_in_wallet','used_special_discount','churn_risk_score']\n",
    "df_train_balanced_num = final_df_train[nums_train]\n",
    "nums_test = ['days_since_last_login','avg_time_spent','avg_transaction_value','avg_frequency_login_days',\n",
    "'points_in_wallet','used_special_discount']\n",
    "df_test_balanced_num = final_df_test[nums_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ed5f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_train = pd.concat([df_train_balanced_num,df_train_balanced],axis=1)\n",
    "final_df_test = pd.concat([df_test_balanced_num,df_test_balanced],axis=1)\n",
    "final_df_train.drop('used_special_discount',axis=1,inplace=True)\n",
    "final_df_test.drop('used_special_discount',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b153aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df_train.drop(['churn_risk_score'],axis=1).values\n",
    "Y = final_df_train['churn_risk_score'].values\n",
    "\n",
    "# Applying SMOTE Over Sampling Strategy for balancing dataset\n",
    "oversample = SMOTE()\n",
    "X_ov,Y_ov = oversample.fit_resample(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad64439",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_ov = scaler.fit_transform(X_ov)\n",
    "X_test = final_df_test.values\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b9995f",
   "metadata": {},
   "source": [
    "### Feature Importance and Identifying Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19e07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = final_df_train.drop(['churn_risk_score'] ,axis = 1)\n",
    "Target = final_df_train['churn_risk_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead43de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(Features, Target, test_size=0.20, random_state=42)\n",
    "model =  RandomForestClassifier(random_state = 0)\n",
    "model.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5699a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = pd.DataFrame({'Features': X_train1.columns, 'Importance': model.feature_importances_})\n",
    "selected_features = important_features.loc[(important_features[\"Importance\"] >= 0.01)]\n",
    "important_features = selected_features.sort_values('Importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b002c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style('white')\n",
    "sns.barplot(x = 'Importance', y = 'Features', data = important_features, palette = 'Spectral' )\n",
    "plt.title('Feature Importance', y = 1.02,  fontsize=25, fontweight = 'bold')\n",
    "plt.xlabel('Importance', labelpad = 15, fontsize = 18)\n",
    "plt.ylabel('Features', labelpad = 15, fontsize = 18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace5cc81",
   "metadata": {},
   "source": [
    "### Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8943d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X_ov,Y_ov,train_size=0.7)\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06f788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RANDOM FOREST CLASSIFIER\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000,max_depth=25)\n",
    "rf.fit(x_train,y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "print(classification_report(y_true=y_test,y_pred=y_pred))\n",
    "print(f1_score(y_true=y_test,y_pred=y_pred,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf036a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,8))\n",
    "sns.set_style('white')\n",
    "cm = confusion_matrix(y_true=y_test,y_pred=y_pred)\n",
    "sns.heatmap(cm, annot=True, ax = ax, cmap = 'Blues', fmt = 'g')\n",
    "plt.title('Correlation Plot for Random Forest Classifier', y = 1.02,  fontsize=18, fontweight = 'bold')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('Actual Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1b29e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLP Classifier with 3 hidden layers of decreasing nodes\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(120,95,70))\n",
    "mlp.fit(x_train,y_train)\n",
    "y_pred = mlp.predict(x_test)\n",
    "print(classification_report(y_true=y_test,y_pred=y_pred))\n",
    "print(f1_score(y_true=y_test,y_pred=y_pred,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7769edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,8))\n",
    "sns.set_style('white')\n",
    "cm = confusion_matrix(y_true=y_test,y_pred=y_pred)\n",
    "sns.heatmap(cm, annot=True, ax = ax, cmap = 'Blues',fmt = 'g')\n",
    "plt.title('Correlation Plot for MLP Classifier', y = 1.02,  fontsize=18, fontweight = 'bold')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('Actual Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e486f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradient Boosting Classifier\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=1000,max_depth=25,min_samples_leaf = 4, min_samples_split= 5)\n",
    "gb.fit(x_train,y_train)\n",
    "y_pred = gb.predict(x_test)\n",
    "print(classification_report(y_true=y_test,y_pred=y_pred))\n",
    "print(f1_score(y_true=y_test,y_pred=y_pred,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66cc9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,8))\n",
    "sns.set_style('white')\n",
    "cm = confusion_matrix(y_true=y_test,y_pred=y_pred)\n",
    "sns.heatmap(cm, annot=True, ax = ax, cmap = 'Blues', fmt = 'g')\n",
    "plt.title('Correlation Plot for Gradient Boosting Classifier', y = 1.02,  fontsize=18, fontweight = 'bold')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('Actual Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6ced2f",
   "metadata": {},
   "source": [
    "### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae3bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "y_pred2tr = rf.predict(x_train)\n",
    "y_pred3tr = mlp.predict(x_train)\n",
    "y_pred4tr = gb.predict(x_train)\n",
    "\n",
    "# Testing\n",
    "y_pred2 = rf.predict(x_test)\n",
    "y_pred3 = mlp.predict(x_test)\n",
    "y_pred4 = gb.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706f6f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_test , ypred):\n",
    "    auc = accuracy_score(y_test , ypred)\n",
    "    return auc\n",
    "\n",
    "def f1(y_test , ypred):\n",
    "    f = f1_score(y_test, ypred, average='macro')\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c253b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Comparison Table\n",
    "results = pd.DataFrame({'Prediction Model':['Random Forest','MLP','Gradient Boosting'],\n",
    "                    'Training Accuracy (%)':[accuracy(y_train,y_pred2tr), accuracy(y_train,y_pred3tr), accuracy(y_train,y_pred4tr)],\n",
    "                    'Testing Accuracy (%)':[accuracy(y_test,y_pred2), accuracy(y_test,y_pred3), accuracy(y_test,y_pred4)],\n",
    "                    'Testing f1-score (%)':[f1(y_test,y_pred2), f1(y_test,y_pred3), f1(y_test,y_pred4)]})\n",
    "results.style.highlight_max(color = 'lightgreen', subset = 'Testing Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f8c9ad",
   "metadata": {},
   "source": [
    "## --- Churn Prediction with Segmentation Method # 2 -  K Means / Mini Batch K Means --- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b067c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use standard scaler to scale and standardize variables\n",
    "\n",
    "col_names = ['days_since_last_login', 'avg_time_spent', 'avg_transaction_value', 'avg_frequency_login_days',\n",
    "            'points_in_wallet', 'churn_risk_score', 'gender_F', 'gender_M', 'region_category_City',\n",
    "            'region_category_Town', 'region_category_Village', 'membership_category_Basic Membership',\n",
    "            'membership_category_Gold Membership', 'membership_category_No Membership', 'membership_category_Platinum Membership',\n",
    "            'membership_category_Premium Membership', 'membership_category_Silver Membership', 'joined_through_referral_No',\n",
    "            'joined_through_referral_Yes', 'preferred_offer_types_Credit/Debit Card Offers',\n",
    "            'preferred_offer_types_Gift Vouchers/Coupons', 'preferred_offer_types_Without Offers',\n",
    "            'medium_of_operation_Both', 'medium_of_operation_Desktop', 'medium_of_operation_Smartphone',\n",
    "            'internet_option_Fiber_Optic', 'internet_option_Mobile_Data', 'internet_option_Wi-Fi', 'used_special_discount_No',\n",
    "            'used_special_discount_Yes', 'offer_application_preference_No', 'offer_application_preference_Yes',\n",
    "            'past_complaint_No', 'past_complaint_Yes', 'complaint_status_No Information Available',\n",
    "            'complaint_status_Not Applicable', 'complaint_status_Solved', 'complaint_status_Solved in Follow-up',\n",
    "            'complaint_status_Unsolved', 'feedback_No reason specified', 'feedback_Poor Customer Service',\n",
    "            'feedback_Poor Product Quality', 'feedback_Poor Website', 'feedback_Products always in Stock',\n",
    "            'feedback_Quality Customer Care', 'feedback_Quality Customer Care', 'feedback_Reasonable Price',\n",
    "            'feedback_Too many ads', 'feedback_User Friendly Website']\n",
    "sd=StandardScaler()\n",
    "features = final_df_train[col_names]\n",
    "scaler = sd.fit(features.values)\n",
    "features = scaler.transform(features.values)\n",
    "scaled_features = pd.DataFrame(features, columns = col_names)\n",
    "scaled_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea63c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "principalComponents = pca.fit_transform(scaled_features)\n",
    "features = range(pca.n_components_)\n",
    "plt.figure(figsize=(16,8))\n",
    "bar_colors = ['tab:green', 'tab:green', 'tab:green', 'tab:orange', 'tab:blue']\n",
    "plt.bar(features, pca.explained_variance_ratio_, color = bar_colors)\n",
    "plt.title('PCA Features Variance Plot', y = 1.02,  fontsize=18, fontweight = 'bold')\n",
    "plt.xlabel('PCA Features', labelpad = 15,  fontsize=14)\n",
    "plt.ylabel('Variance Percent (%)', labelpad = 15,  fontsize=14)\n",
    "plt.xticks(features, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "PCA_components = pd.DataFrame(principalComponents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfc8ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using KElbowVisualizer package from yellowbricks to create elbow plot\n",
    "model = KMeans()\n",
    "elbowplot = KElbowVisualizer(model, k=(1,50),size=(1080, 500))\n",
    "elbowplot.fit(PCA_components.iloc[:,:3])\n",
    "elbowplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b3016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model = KMeans(n_clusters=6, init='k-means++',random_state=42)\n",
    "kmeans_model.fit(PCA_components.iloc[:,:2])\n",
    "\n",
    "print(\"silhouette_score is :\",silhouette_score(PCA_components.iloc[:,:2], model.labels_, metric='euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b1b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = model.predict(PCA_components.iloc[:,:3])\n",
    "cluster_df = pd.DataFrame(final_df_train)\n",
    "cluster_df['cluster'] = kmeans\n",
    "cluster_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec11ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df = final_df_train.groupby(['cluster'], as_index=False).mean()\n",
    "avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3391cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=1, ncols=4, figsize=(18, 8))\n",
    "sns.set_style('white')\n",
    "sns.set(font_scale=1.5)\n",
    "sns.barplot(x='cluster',y='avg_transaction_value',data=avg_df ,ax=ax[0], palette = 'Spectral')\n",
    "sns.barplot(x='cluster',y='points_in_wallet',data=avg_df, ax=ax[1], palette = 'Spectral')\n",
    "sns.barplot(x='cluster',y='feedback_Products always in Stock',data=avg_df, ax=ax[2], palette = 'Spectral')\n",
    "sns.barplot(x='cluster',y='feedback_Quality Customer Care',data=avg_df, ax=ax[3], palette = 'Spectral')\n",
    "plt.suptitle('Total Count per Variable Based on Cluster', y = 0.9,  fontsize=18, fontweight = 'bold')\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.8, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052bfc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "f, ax = plt.subplots(nrows=1, ncols=4, figsize=(18, 8))\n",
    "sns.set(font_scale=1.5)\n",
    "sns.barplot(x='cluster',y='avg_frequency_login_days',data=avg_df ,ax=ax[0], palette = 'Spectral')\n",
    "sns.barplot(x='cluster',y='churn_risk_score',data=avg_df, ax=ax[1], palette = 'Spectral')\n",
    "sns.barplot(x='cluster',y='feedback_Poor Customer Service',data=avg_df, ax=ax[2], palette = 'Spectral')\n",
    "sns.barplot(x='cluster',y='feedback_Poor Website',data=avg_df, ax=ax[3], palette = 'Spectral')\n",
    "#plt.suptitle('', y = 0.9,  fontsize=18, fontweight = 'bold')\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.8, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1f8ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names_test = ['days_since_last_login', 'avg_time_spent', 'avg_transaction_value', 'avg_frequency_login_days',\n",
    "            'points_in_wallet', 'gender_F', 'gender_M', 'region_category_City',\n",
    "            'region_category_Town', 'region_category_Village', 'membership_category_Basic Membership',\n",
    "            'membership_category_Gold Membership', 'membership_category_No Membership', 'membership_category_Platinum Membership',\n",
    "            'membership_category_Premium Membership', 'membership_category_Silver Membership', 'joined_through_referral_No',\n",
    "            'joined_through_referral_Yes', 'preferred_offer_types_Credit/Debit Card Offers',\n",
    "            'preferred_offer_types_Gift Vouchers/Coupons', 'preferred_offer_types_Without Offers',\n",
    "            'medium_of_operation_Both', 'medium_of_operation_Desktop', 'medium_of_operation_Smartphone',\n",
    "            'internet_option_Fiber_Optic', 'internet_option_Mobile_Data', 'internet_option_Wi-Fi', 'used_special_discount_No',\n",
    "            'used_special_discount_Yes', 'offer_application_preference_No', 'offer_application_preference_Yes',\n",
    "            'past_complaint_No', 'past_complaint_Yes', 'complaint_status_No Information Available',\n",
    "            'complaint_status_Not Applicable', 'complaint_status_Solved', 'complaint_status_Solved in Follow-up',\n",
    "            'complaint_status_Unsolved', 'feedback_No reason specified', 'feedback_Poor Customer Service',\n",
    "            'feedback_Poor Product Quality', 'feedback_Poor Website', 'feedback_Products always in Stock',\n",
    "            'feedback_Quality Customer Care', 'feedback_Quality Customer Care', 'feedback_Reasonable Price',\n",
    "            'feedback_Too many ads', 'feedback_User Friendly Website']\n",
    "sd_test=StandardScaler()\n",
    "features_test = final_df_test[col_names_test]\n",
    "scaler_test = sd_test.fit(features_test.values)\n",
    "features_test = scaler_test.transform(features_test.values)\n",
    "scaled_features_test = pd.DataFrame(features_test, columns = col_names_test)\n",
    "scaled_features_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c650e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_test = PCA(n_components=5)\n",
    "principalComponents_test = pca_test.fit_transform(scaled_features_test)\n",
    "features_test = range(pca_test.n_components_)\n",
    "plt.figure(figsize=(16,8))\n",
    "bar_colors = ['tab:green', 'tab:green', 'tab:green', 'tab:orange', 'tab:blue']\n",
    "plt.bar(features_test, pca_test.explained_variance_ratio_, color = bar_colors)\n",
    "plt.title('PCA Features Variance Plot', y = 1.02,  fontsize=18, fontweight = 'bold')\n",
    "plt.xlabel('PCA Features', labelpad = 15,  fontsize=14)\n",
    "plt.ylabel('Variance Percent (%)', labelpad = 15,  fontsize=14)\n",
    "plt.xticks(features, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "PCA_components_test = pd.DataFrame(principalComponents_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29664a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model_test = KMeans()\n",
    "elbowplot_test = KElbowVisualizer(kmeans_model_test, k=(1,50),size=(1080, 500))\n",
    "elbowplot_test.fit(PCA_components_test.iloc[:,:3])        \n",
    "elbowplot_test.show()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ecdfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = KMeans(n_clusters=5, init='k-means++',random_state=42)\n",
    "model_test.fit(PCA_components_test.iloc[:,:2])\n",
    "print(\"silhouette_score is :\",silhouette_score(PCA_components_test.iloc[:,:2], model_test.labels_, metric='euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8b0622",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_test = model_test.predict(PCA_components_test.iloc[:,:2])\n",
    "cluster_df_test = pd.DataFrame(final_df_test)\n",
    "cluster_df_test['cluster'] = kmeans_test\n",
    "cluster_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d874ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new datasets based on each cluster (subset datasets)\n",
    "\n",
    "grouped = cluster_df.groupby('cluster')\n",
    " \n",
    "df_grouped_0 = grouped.get_group(0)\n",
    "df_grouped_0 = pd.DataFrame(df_grouped_0)\n",
    "\n",
    "df_grouped_1 = grouped.get_group(1)\n",
    "df_grouped_1 = pd.DataFrame(df_grouped_1)\n",
    "\n",
    "df_grouped_2 = grouped.get_group(2)\n",
    "df_grouped_2 = pd.DataFrame(df_grouped_2)\n",
    "\n",
    "df_grouped_3 = grouped.get_group(3)\n",
    "df_grouped_3 = pd.DataFrame(df_grouped_3)\n",
    "\n",
    "df_grouped_4 = grouped.get_group(4)\n",
    "df_grouped_4 = pd.DataFrame(df_grouped_4)\n",
    "\n",
    "df_grouped_5 = grouped.get_group(5)\n",
    "df_grouped_5 = pd.DataFrame(df_grouped_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4237da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = df_grouped_2.drop(['churn_risk_score'],axis=1).values\n",
    "Y_0 = df_grouped_2['churn_risk_score'].values\n",
    "\n",
    "oversample = SMOTE()\n",
    "X_ov_0,Y_ov_0 = oversample.fit_resample(X_0,Y_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29f292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_ov_0 = scaler.fit_transform(X_ov_0)\n",
    "X_test_0 = cluster_df_test.values\n",
    "X_test_0 = scaler.transform(X_test_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a07290",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2,x_test2,y_train2,y_test2 = train_test_split(X_ov_0,Y_ov_0,train_size=0.7)\n",
    "print(x_train2.shape,y_train2.shape)\n",
    "print(x_test2.shape,y_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57c10f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RANDOM FOREST CLASSIFIER\n",
    "\n",
    "rf2 = RandomForestClassifier(n_estimators=1000,max_depth=25)\n",
    "rf2.fit(x_train2,y_train2)\n",
    "y_pred2 = rf2.predict(x_test2)\n",
    "print(classification_report(y_true=y_test2,y_pred=y_pred2))\n",
    "print(f1_score(y_true=y_test2,y_pred=y_pred2,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034bd94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLP Classifier with decreasing node sizes\n",
    "\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(120,95,70))\n",
    "mlp2.fit(x_train2,y_train2)\n",
    "y_pred2 = mlp2.predict(x_test2)\n",
    "print(classification_report(y_true=y_test2,y_pred=y_pred2))\n",
    "print(f1_score(y_true=y_test2,y_pred=y_pred2,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa81e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradient Boosting Classifier\n",
    "\n",
    "gb2 = GradientBoostingClassifier(n_estimators=1000, max_depth=25,min_samples_leaf = 4, min_samples_split= 5)\n",
    "gb2.fit(x_train2,y_train2)\n",
    "y_pred2 = gb2.predict(x_test2)\n",
    "print(classification_report(y_true=y_test2,y_pred=y_pred2))\n",
    "print(f1_score(y_true=y_test2,y_pred=y_pred2,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c737f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "y_pred2tr2 = rf2.predict(x_train2)\n",
    "y_pred3tr2 = mlp2.predict(x_train2)\n",
    "y_pred4tr2 = gb2.predict(x_train2)\n",
    "\n",
    "# Testing\n",
    "y_pred2_2 = rf2.predict(x_test2)\n",
    "y_pred3_2 = mlp2.predict(x_test2)\n",
    "y_pred4_2 = gb2.predict(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Comparison Table - Cluster 0 \n",
    "\n",
    "results2 = pd.DataFrame({'Prediction Model':['Random Forest','MLP','Gradient Boosting'],\n",
    "                    'Training Accuracy (%)':[accuracy(y_train2,y_pred2tr2), accuracy(y_train2,y_pred3tr2), accuracy(y_train2,y_pred4tr2)],\n",
    "                    'Testing Accuracy (%)':[accuracy(y_test2,y_pred2_2), accuracy(y_test2,y_pred3_2), accuracy(y_test2,y_pred4_2)],\n",
    "                    'Testing f1-score (%)':[f1(y_test2,y_pred2_2), f1(y_test2,y_pred3_2), f1(y_test2,y_pred4_2)]})\n",
    "\n",
    "results2.style.highlight_max(color = 'lightgreen', subset = 'Testing Accuracy (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81683986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR CLUSTER 4\n",
    "X_1 = df_grouped_4.drop(['churn_risk_score'],axis=1).values\n",
    "Y_1 = df_grouped_4['churn_risk_score'].values\n",
    "\n",
    "oversample = SMOTE()\n",
    "X_ov_1,Y_ov_1 = oversample.fit_resample(X_1,Y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c7097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_ov_1 = scaler.fit_transform(X_ov_1)\n",
    "X_test_1 = cluster_df_test.values\n",
    "X_test_1 = scaler.transform(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f95f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train3,x_test3,y_train3,y_test3 = train_test_split(X_ov_1,Y_ov_1,train_size=0.7)\n",
    "print(x_train3.shape,y_train3.shape)\n",
    "print(x_test3.shape,y_test3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d7741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RANDOM FOREST CLASSIFIER\n",
    "\n",
    "rf3 = RandomForestClassifier(n_estimators=1000,max_depth=25)\n",
    "rf3.fit(x_train3,y_train3)\n",
    "y_pred3 = rf3.predict(x_test3)\n",
    "print(classification_report(y_true=y_test3,y_pred=y_pred3))\n",
    "print(f1_score(y_true=y_test3,y_pred=y_pred3,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f9d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLP Classifier with 3 hidden layers of decreasing nodes\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp3 = MLPClassifier(hidden_layer_sizes=(120,95,70))\n",
    "mlp3.fit(x_train3,y_train3)\n",
    "y_pred3 = mlp3.predict(x_test3)\n",
    "print(classification_report(y_true=y_test3,y_pred=y_pred3))\n",
    "print(f1_score(y_true=y_test3,y_pred=y_pred3,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a3972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradient Boosting Classifier\n",
    "\n",
    "gb3 = GradientBoostingClassifier(n_estimators=1000,max_depth=25,min_samples_leaf = 4, min_samples_split= 5)\n",
    "gb3.fit(x_train3,y_train3)\n",
    "y_pred3 = gb3.predict(x_test3)\n",
    "print(classification_report(y_true=y_test3,y_pred=y_pred3))\n",
    "print(f1_score(y_true=y_test3,y_pred=y_pred3,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e21ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "y_pred2tr3 = rf3.predict(x_train3)\n",
    "y_pred3tr3 = mlp3.predict(x_train3)\n",
    "y_pred4tr3 = gb3.predict(x_train3)\n",
    "\n",
    "# Testing\n",
    "y_pred2_3 = rf3.predict(x_test3)\n",
    "y_pred3_3 = mlp3.predict(x_test3)\n",
    "y_pred4_3 = gb3.predict(x_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d7e06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Comparison Table - Cluster 4\n",
    "\n",
    "results3 = pd.DataFrame({'Prediction Model':['Random Forest','MLP','Gradient Boosting'],\n",
    "                    'Training Accuracy (%)':[accuracy(y_train3,y_pred2tr3), accuracy(y_train3,y_pred3tr3), accuracy(y_train3,y_pred4tr3)],\n",
    "                    'Testing Accuracy (%)':[accuracy(y_test3,y_pred2_3), accuracy(y_test3,y_pred3_3), accuracy(y_test3,y_pred4_3)],\n",
    "                    'Testing f1-score (%)':[f1(y_test3,y_pred2_3), f1(y_test3,y_pred3_3), f1(y_test3,y_pred4_3)]})\n",
    "results3.style.highlight_max(color = 'lightgreen', subset = 'Testing Accuracy (%)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae8eceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR CLUSTER 3\n",
    "X_3 = df_grouped_3.drop(['churn_risk_score'],axis=1).values\n",
    "Y_3 = df_grouped_3['churn_risk_score'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5602cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_ov_3,Y_ov_3 = oversample.fit_resample(X_3,Y_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfe76e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_ov_3 = scaler.fit_transform(X_ov_3)\n",
    "X_test_3 = cluster_df_test.values\n",
    "X_test_3 = scaler.transform(X_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ab5592",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train4,x_test4,y_train4,y_test4 = train_test_split(X_ov_3,Y_ov_3,train_size=0.7)\n",
    "print(x_train4.shape,y_train4.shape)\n",
    "print(x_test4.shape,y_test4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d1fd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RANDOM FOREST CLASSIFIER\n",
    "\n",
    "rf4 = RandomForestClassifier(n_estimators=1000,max_depth=25)\n",
    "rf4.fit(x_train4,y_train4)\n",
    "y_pred4 = rf4.predict(x_test4)\n",
    "print(classification_report(y_true=y_test4,y_pred=y_pred4))\n",
    "print(f1_score(y_true=y_test4,y_pred=y_pred4,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d38b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLP Classifier with 3 hidden layers of decreasing nodes\n",
    "\n",
    "mlp4 = MLPClassifier(hidden_layer_sizes=(120,95,70))\n",
    "mlp4.fit(x_train4,y_train4)\n",
    "y_pred4 = mlp4.predict(x_test4)\n",
    "print(classification_report(y_true=y_test4,y_pred=y_pred4))\n",
    "print(f1_score(y_true=y_test4,y_pred=y_pred4,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3292046",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradient Boosting Classifier\n",
    "\n",
    "gb4 = GradientBoostingClassifier(n_estimators=100,max_depth=10,min_samples_leaf = 4, min_samples_split= 5)\n",
    "gb4.fit(x_train4,y_train4)\n",
    "y_pred4 = gb4.predict(x_test4)\n",
    "print(classification_report(y_true=y_test4,y_pred=y_pred4))\n",
    "print(f1_score(y_true=y_test4,y_pred=y_pred4,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf48ff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "y_pred2tr4 = rf4.predict(x_train4)\n",
    "y_pred3tr4 = mlp4.predict(x_train4)\n",
    "y_pred4tr4 = gb4.predict(x_train4)\n",
    "\n",
    "# Testing\n",
    "y_pred2_4 = rf4.predict(x_test4)\n",
    "y_pred3_4 = mlp4.predict(x_test4)\n",
    "y_pred4_4 = gb4.predict(x_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2969290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Comparison Table - Cluster 3\n",
    "\n",
    "results4 = pd.DataFrame({'Prediction Model':['Random Forest','MLP','Gradient Boosting'],\n",
    "                    'Training Accuracy (%)':[accuracy(y_train4,y_pred2tr4), accuracy(y_train4,y_pred3tr4), accuracy(y_train4,y_pred4tr4)],\n",
    "                    'Testing Accuracy (%)':[accuracy(y_test4,y_pred2_4), accuracy(y_test4,y_pred3_4), accuracy(y_test4,y_pred4_4)],\n",
    "                    'Testing f1-score (%)':[f1(y_test4,y_pred2_4), f1(y_test4,y_pred3_4), f1(y_test4,y_pred4_4)]}\n",
    "                    )\n",
    "\n",
    "results4.style.highlight_max(color = 'lightgreen', subset = 'Testing Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0d1a72",
   "metadata": {},
   "source": [
    "## --- Churn Prediction with Segmentation Method # 3 -  DBSCAN --- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5f21e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.8, min_samples=9)\n",
    "db_clusters = dbscan.fit_predict(PCA_components.iloc[:,:2])\n",
    "print(db_clusters)\n",
    "cluster_df['dbscan_cluster'] = db_clusters\n",
    "cluster_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec5f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df_db = cluster_df.groupby(['dbscan_cluster'], as_index=False).mean()\n",
    "avg_df_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b3d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_test = DBSCAN(eps=0.8, min_samples=9)\n",
    "db_clusters_test = dbscan_test.fit_predict(PCA_components_test.iloc[:,:2])\n",
    "print(db_clusters_test)\n",
    "cluster_df_test['dbscan_cluster'] = db_clusters_test\n",
    "cluster_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda995cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "f, ax = plt.subplots(nrows=1, ncols=4, figsize=(18, 5))\n",
    "sns.set(font_scale=1.5)\n",
    "sns.barplot(x='dbscan_cluster',y='days_since_last_login',data=avg_df_db ,ax=ax[0], palette = 'Spectral')\n",
    "sns.barplot(x='dbscan_cluster',y='avg_time_spent',data=avg_df_db, ax=ax[1], palette = 'Spectral')\n",
    "sns.barplot(x='dbscan_cluster',y='avg_transaction_value',data=avg_df_db, ax=ax[2], palette = 'Spectral')\n",
    "sns.barplot(x='dbscan_cluster',y='avg_frequency_login_days',data=avg_df_db, ax=ax[3], palette = 'Spectral')\n",
    "plt.suptitle('Total Count per Variable Based on Cluster', y = 0.9,  fontsize=18, fontweight = 'bold')\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.8, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d638d058",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "f, ax = plt.subplots(nrows=1, ncols=4, figsize=(18, 5))\n",
    "sns.set(font_scale=1.5)\n",
    "sns.barplot(x='dbscan_cluster',y='points_in_wallet',data=avg_df_db ,ax=ax[0], palette = 'Spectral')\n",
    "sns.barplot(x='dbscan_cluster',y='churn_risk_score',data=avg_df_db, ax=ax[1], palette = 'Spectral')\n",
    "sns.barplot(x='dbscan_cluster',y='membership_category_Basic Membership',data=avg_df_db, ax=ax[2], palette = 'Spectral')\n",
    "sns.barplot(x='dbscan_cluster',y='membership_category_No Membership',data=avg_df_db, ax=ax[3], palette = 'Spectral')\n",
    "#plt.suptitle('Total Count per Variable Based on Cluster', y = 0.9,  fontsize=18, fontweight = 'bold')\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.8, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f2ba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new datasets based on each cluster (subset datasets)\n",
    "\n",
    "grouped3 = cluster_df.groupby('dbscan_cluster')\n",
    " \n",
    "df_grouped_00 = grouped.get_group(0)\n",
    "df_grouped_00 = pd.DataFrame(df_grouped_00)\n",
    "\n",
    "df_grouped_11 = grouped.get_group(1)\n",
    "df_grouped_11 = pd.DataFrame(df_grouped_11)\n",
    "\n",
    "df_grouped_22 = grouped.get_group(2)\n",
    "df_grouped_22 = pd.DataFrame(df_grouped_22)\n",
    "\n",
    "df_grouped_33 = grouped.get_group(3)\n",
    "df_grouped_33 = pd.DataFrame(df_grouped_33)\n",
    "\n",
    "df_grouped_44 = grouped.get_group(4)\n",
    "df_grouped_44 = pd.DataFrame(df_grouped_44)\n",
    "\n",
    "df_grouped_55 = grouped.get_group(5)\n",
    "df_grouped_55 = pd.DataFrame(df_grouped_55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d64ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_00 = df_grouped_11.drop(['churn_risk_score'],axis=1).values\n",
    "Y_00 = df_grouped_11['churn_risk_score'].values\n",
    "\n",
    "oversample = SMOTE()\n",
    "X_ov_00,Y_ov_00 = oversample.fit_resample(X_00,Y_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dcd5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_ov_00 = scaler.fit_transform(X_ov_00)\n",
    "X_test_00 = cluster_df_test.values\n",
    "X_test_00 = scaler.transform(X_test_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5db95e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train00,x_test00,y_train00,y_test00 = train_test_split(X_ov_00,Y_ov_00,train_size=0.7)\n",
    "print(x_train00.shape,y_train00.shape)\n",
    "print(x_test00.shape,y_test00.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c52a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RANDOM FOREST CLASSIFIER\n",
    "\n",
    "rf00 = RandomForestClassifier(n_estimators=1000,max_depth=25)\n",
    "rf00.fit(x_train00,y_train00)\n",
    "y_pred00 = rf00.predict(x_test00)\n",
    "print(classification_report(y_true=y_test00,y_pred=y_pred00))\n",
    "print(f1_score(y_true=y_test00,y_pred=y_pred00,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aa3e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLP Classifier with 3 hidden layers of decreasing nodes\n",
    "\n",
    "mlp00 = MLPClassifier(hidden_layer_sizes=(120,95,70))\n",
    "mlp00.fit(x_train00,y_train00)\n",
    "y_pred00 = mlp00.predict(x_test00)\n",
    "print(classification_report(y_true=y_test00,y_pred=y_pred00))\n",
    "print(f1_score(y_true=y_test00,y_pred=y_pred00,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc10af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradient Boosting Classifier\n",
    "\n",
    "gb00 = GradientBoostingClassifier(n_estimators=1000,max_depth=25,min_samples_leaf = 4, min_samples_split= 5)\n",
    "gb00.fit(x_train00,y_train00)\n",
    "y_pred00 = gb00.predict(x_test00)\n",
    "print(classification_report(y_true=y_test00,y_pred=y_pred00))\n",
    "print(f1_score(y_true=y_test00,y_pred=y_pred00,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "y_pred2tr00 = rf00.predict(x_train00)\n",
    "y_pred3tr00 = mlp00.predict(x_train00)\n",
    "y_pred4tr00 = gb00.predict(x_train00)\n",
    "\n",
    "# Testing\n",
    "y_pred20 = rf00.predict(x_test00)\n",
    "y_pred30 = mlp00.predict(x_test00)\n",
    "y_pred40 = gb00.predict(x_test00)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81420b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Comparison Table - Cluster 1 - DBSCAN\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "results9 = pd.DataFrame({'Prediction Model':['Random Forest','MLP','Gradient Boosting'],\n",
    "                    'Training Accuracy (%)':[accuracy(y_train00,y_pred2tr00), accuracy(y_train00,y_pred3tr00), accuracy(y_train00,y_pred4tr00)],\n",
    "                    'Testing Accuracy (%)':[accuracy(y_test00,y_pred20), accuracy(y_test00,y_pred30), accuracy(y_test00,y_pred40)],\n",
    "                    'Testing f1-Score (%)':[f1(y_test00,y_pred20), f1(y_test00,y_pred30), f1(y_test00,y_pred40)]}\n",
    "                    )\n",
    "\n",
    "results9.style.highlight_max(color = 'lightgreen', subset = 'Testing Accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a037a017",
   "metadata": {},
   "source": [
    "## --- Churn Prediction with Segmentation Method # 4 -  GMM --- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_type =['full','tied','diag','spherical']\n",
    "num_clusters=np.arange(1,12)\n",
    "results_=pd.DataFrame(columns=['Covariance Type','# of Clusters','Silhouette Score','Davies Bouldin Score'])\n",
    "for i in cov_type:\n",
    "    for x in num_clusters:       \n",
    "        gmm_cluster=GaussianMixture(n_components=x,covariance_type=i,random_state=5)\n",
    "        clusters=gmm_cluster.fit_predict(PCA_components.iloc[:,:2])\n",
    "        if len(np.unique(clusters))>=2:\n",
    "            results_=results_.append({\"Covariance Type\":i,'# of Clusters':x,\n",
    "                                      \"Silhouette Score\":metrics.silhouette_score(PCA_components.iloc[:,:2],clusters),\n",
    "                                      'Davies Bouldin Score':metrics.davies_bouldin_score(PCA_components.iloc[:,:2],clusters)},ignore_index=True)\n",
    "display(results_.sort_values(by=[\"Silhouette Score\"], ascending=False)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab7351",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm2=GaussianMixture(n_components=6, covariance_type='spherical',max_iter=2000, random_state=5).fit(PCA_components.iloc[:,:2])\n",
    "labels = gmm2.predict(PCA_components.iloc[:,:2])\n",
    "cluster_df = pd.DataFrame(final_df_train)\n",
    "cluster_df['gmm_cluster'] = labels\n",
    "cluster_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ddcd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df_gmm = cluster_df.groupby(['gmm_cluster'], as_index=False).mean()\n",
    "avg_df_gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39c6acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "f, ax = plt.subplots(nrows=1, ncols=4, figsize=(18, 5))\n",
    "sns.set(font_scale=1.5)\n",
    "sns.barplot(x='gmm_cluster',y='days_since_last_login',data=avg_df_gmm ,ax=ax[0], palette = 'Spectral')\n",
    "sns.barplot(x='gmm_cluster',y='avg_time_spent',data=avg_df_gmm, ax=ax[1], palette = 'Spectral')\n",
    "sns.barplot(x='gmm_cluster',y='avg_transaction_value',data=avg_df_gmm, ax=ax[2], palette = 'Spectral')\n",
    "sns.barplot(x='gmm_cluster',y='avg_frequency_login_days',data=avg_df_gmm, ax=ax[3], palette = 'Spectral')\n",
    "plt.suptitle('Total Count per Variable Based on Cluster', y = 0.9,  fontsize=18, fontweight = 'bold')\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.8, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5f1ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "f, ax = plt.subplots(nrows=1, ncols=4, figsize=(18, 5))\n",
    "sns.set(font_scale=1.5)\n",
    "sns.barplot(x='gmm_cluster',y='points_in_wallet',data=avg_df_gmm ,ax=ax[0], palette = 'Spectral')\n",
    "sns.barplot(x='gmm_cluster',y='churn_risk_score',data=avg_df_gmm, ax=ax[1], palette = 'Spectral')\n",
    "sns.barplot(x='gmm_cluster',y='membership_category_Basic Membership',data=avg_df_gmm, ax=ax[2], palette = 'Spectral')\n",
    "sns.barplot(x='gmm_cluster',y='membership_category_No Membership',data=avg_df_gmm, ax=ax[3], palette = 'Spectral')\n",
    "#plt.suptitle('Total Count per Variable Based on Cluster', y = 0.9,  fontsize=18, fontweight = 'bold')\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.8, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60c881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_type=['full','tied','diag','spherical']\n",
    "num_clusters=np.arange(1,12)\n",
    "results_=pd.DataFrame(columns=['Covariance Type','# of Clusters','Silhouette Score','Davies Bouldin Score'])\n",
    "for i in cov_type:\n",
    "    for x in num_clusters:       \n",
    "        gmm_cluster=GaussianMixture(n_components=n,covariance_type=i,random_state=5)\n",
    "        clusters=gmm_cluster.fit_predict(PCA_components_test.iloc[:,:2])\n",
    "        if len(np.unique(clusters))>=2:\n",
    "            results_=results_.append({\"Covariance type\":i,'# of Clusters':x,\n",
    "                                      \"Silhouette Score\":metrics.silhouette_score(PCA_components_test.iloc[:,:2],clusters),\n",
    "                                      'Davies Bouldin Score':metrics.davies_bouldin_score(PCA_components_test.iloc[:,:2],clusters)},ignore_index=True)\n",
    "display(results_.sort_values(by=[\"Silhouette Score\"], ascending=False)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ab496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm3=GaussianMixture(n_components=6, covariance_type='full',max_iter=2000, random_state=5).fit(PCA_components_test.iloc[:,:2])\n",
    "labels_test = gmm3.predict(PCA_components_test.iloc[:,:2])\n",
    "cluster_df_test = pd.DataFrame(final_df_test)\n",
    "cluster_df_test['gmm_cluster'] = labels_test\n",
    "cluster_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af30a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new datasets based on each cluster (subset datasets)\n",
    "grouped3 = cluster_df.groupby('gmm_cluster')\n",
    " \n",
    "df2_grouped_0 = grouped3.get_group(0)\n",
    "df2_grouped_0 = pd.DataFrame(df2_grouped_0)\n",
    "\n",
    "df2_grouped_1 = grouped3.get_group(1)\n",
    "df2_grouped_1 = pd.DataFrame(df2_grouped_1)\n",
    "\n",
    "df2_grouped_2 = grouped3.get_group(2)\n",
    "df2_grouped_2 = pd.DataFrame(df2_grouped_2)\n",
    "\n",
    "df2_grouped_3 = grouped3.get_group(3)\n",
    "df2_grouped_3 = pd.DataFrame(df2_grouped_3)\n",
    "\n",
    "df2_grouped_4 = grouped3.get_group(4)\n",
    "df2_grouped_4 = pd.DataFrame(df2_grouped_4)\n",
    "\n",
    "df2_grouped_5 = grouped3.get_group(5)\n",
    "df2_grouped_5 = pd.DataFrame(df2_grouped_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d0495",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_10 = df2_grouped_0.drop(['churn_risk_score'],axis=1).values\n",
    "Y_10 = df2_grouped_0['churn_risk_score'].values\n",
    "\n",
    "oversample = SMOTE()\n",
    "X_ov_10,Y_ov_10 = oversample.fit_resample(X_10,Y_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccf1558",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train5,x_test5,y_train5,y_test5 = train_test_split(X_ov_10,Y_ov_10,train_size=0.7)\n",
    "print(x_train5.shape,y_train5.shape)\n",
    "print(x_test5.shape,y_test5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739d2714",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RANDOM FOREST CLASSIFIER\n",
    "\n",
    "rf10 = RandomForestClassifier(n_estimators=1000,max_depth=25)\n",
    "rf10.fit(x_train5,y_train5)\n",
    "y_pred5 = rf10.predict(x_test5)\n",
    "print(classification_report(y_true=y_test5,y_pred=y_pred5))\n",
    "print(f1_score(y_true=y_test5,y_pred=y_pred5,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd795c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLP Classifier with 3 hidden layers of decreasing nodes\n",
    "\n",
    "mlp10 = MLPClassifier(hidden_layer_sizes=(120, 95, 70))\n",
    "mlp10.fit(x_train5,y_train5)\n",
    "y_pred5 = mlp10.predict(x_test5)\n",
    "print(classification_report(y_true=y_test5,y_pred=y_pred5))\n",
    "print(f1_score(y_true=y_test5,y_pred=y_pred5,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fbb110",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradient Boosting Classifier\n",
    "\n",
    "gb10 = GradientBoostingClassifier(n_estimators=1000,max_depth=25,min_samples_leaf = 4, min_samples_split= 5)\n",
    "gb10.fit(x_train5,y_train5)\n",
    "y_pred5 = gb10.predict(x_test5)\n",
    "print(classification_report(y_true=y_test5,y_pred=y_pred5))\n",
    "print(f1_score(y_true=y_test5,y_pred=y_pred5,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422cb82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,8))\n",
    "sns.set_style('white')\n",
    "cm = confusion_matrix(y_true=y_test5,y_pred=y_pred5)\n",
    "sns.heatmap(cm, annot=True, ax = ax, cmap = 'Blues', fmt = 'g')\n",
    "plt.title('Correlation Plot for Gradient Boosting Classifier', y = 1.02,  fontsize=18, fontweight = 'bold')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('Actual Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9641ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "y_pred2tr10 = rf10.predict(x_train5)\n",
    "y_pred3tr10 = mlp10.predict(x_train5)\n",
    "y_pred4tr10 = gb10.predict(x_train5)\n",
    "\n",
    "# Testing\n",
    "y_pred2_10 = rf10.predict(x_test5)\n",
    "y_pred3_10 = mlp10.predict(x_test5)\n",
    "y_pred4_10 = gb10.predict(x_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3d48ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Comparison Table - Cluster 0 \n",
    "\n",
    "results10 = pd.DataFrame({'Prediction Model':['Random Forest','MLP','Gradient Boosting'],\n",
    "                    'Training Accuracy (%)':[accuracy(y_train5,y_pred2tr10), accuracy(y_train5,y_pred3tr10), accuracy(y_train5,y_pred4tr10)],\n",
    "                    'Testing Accuracy (%)':[accuracy(y_test5,y_pred2_10), accuracy(y_test5,y_pred3_10), accuracy(y_test5,y_pred4_10)],\n",
    "                    'Testing f1-score (%)':[f1(y_test5,y_pred2_10), f1(y_test5,y_pred3_10), f1(y_test5,y_pred4_10)]}\n",
    "                    )\n",
    "results10.style.highlight_max(color = 'lightgreen', subset = 'Testing Accuracy (%)')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
